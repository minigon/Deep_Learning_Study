{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-ppe0pXkY1yb",
        "bD3D3lAsY1yc",
        "CdF1yYtGY1zF"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBP19cwDY1xq"
      },
      "source": [
        "# boostcourse_tensorflow2.0_dnn_project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q8ks0jtY1xs"
      },
      "source": [
        "### 실습 전 안내\n",
        "* 실습코드는 <font color='red'>Python 3.6</font>, <font color='red'>TensorFlow 2.0</font>버전을 기준으로 작성되었습니다. 원활한 실습 진행을 위해 버전을 맞춰주시는 것을 권장드립니다.\n",
        "* 간혹 컴퓨터 성능에 따라 모델을 학습시키는 과정에서 시간이 소요될 수 있습니다. 이 경우 <font color='red'>Colab</font>으로 실습을 진행해주시는 것을 권장드립니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAprVA_2Y1xt"
      },
      "source": [
        "## Colab 사용자를 위한 안내\n",
        "\n",
        "해당 노트북은 **로컬** 환경에서 최적화 되어 있습니다. **로컬 환경에서 진행하시는 분**들은 바로 학습을 진행하시면 됩니다.\n",
        "\n",
        "**Colab을 사용하시는 분**들은 처음에 아래 주석을 해제하시고 한번 만 실행시켜주세요!\n",
        "\n",
        "* 주석을 해제하는 방법: 해당 영역을 선택하고, `Ctrl + /` 를 누르면 해당 영역의 주석에 해제됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvOR824oY1xu",
        "outputId": "6d1be118-2ded-41b6-c337-41361819bfad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkVofpdvY1xy"
      },
      "source": [
        "Colab 을 사용하시는 분들은 아래 주석을 해제하시고 `folder` 변수 명에 프로젝트 디렉토리를 저장한 위치를 작성해주세요! 예를 들어, `01_dnn_tf` 의 위치가 \"내 드라이브 > colab_notebook > tensorflow\" 폴더 안에 있는 경우, \"colab_notebook/tensorflow\" 를 작성하시면 됩니다.\n",
        "\n",
        "```python\n",
        "folder = \"colab_notebook/tensorflow\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMAZSAB0Y1xz",
        "outputId": "2b7a6367-59eb-4500-f9f9-e1878c3a2ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# folder 변수에 구글드라이브에 프로젝트를 저장한 디렉토리를 입력하세요!\n",
        "# My Drive 밑에 저장했다면 그대로 두시면 됩니다.\n",
        "folder = \"colab\"\n",
        "project_dir = \"01_dnn_tf\"\n",
        "\n",
        "base_path = Path(\"/content/drive/My Drive/\")\n",
        "project_path = base_path / folder / project_dir\n",
        "os.chdir(project_path)\n",
        "for x in list(project_path.glob(\"*\")):\n",
        "    if x.is_dir():\n",
        "        dir_name = str(x.relative_to(project_path))\n",
        "        os.rename(dir_name, dir_name.split(\" \", 1)[0])\n",
        "print(f\"현재 디렉토리 위치: {os.getcwd()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "현재 디렉토리 위치: /content/drive/My Drive/colab/01_dnn_tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJqGRHd0Y1x2"
      },
      "source": [
        "# Neural Network: FashoinMNIST Classifier\n",
        "\n",
        "![](https://drive.google.com/uc?id=1OSa44ql8zf9kq2r_D_Q0U1WWTkMPcCgm)\n",
        "\n",
        "* 이미지 출처: 네이버\n",
        "<br>\n",
        "스마트 렌즈는 여러분이 찍은 이미지가 어떤 옷인지 판별하고 쇼핑과 연결지어 검색까지 해줍니다. 이러한 기술은 어떻게 만들어 지는 것일까요? 물론 복잡한 기술이 들어가겠지만 여기에는 딥러닝 기술이 포함되어 있습니다. 이번 프로젝트에서는 10 종류의 의류와 관련된 이미지를 학습시키고 판별하는 모델을 만들어 볼것입니다.     \n",
        "\n",
        "이번 실습의 목표는 다음과 같습니다.\n",
        "- [Fashion-Mnist](https://github.com/zalandoresearch/fashion-mnist) 데이터셋을 활용해 분류기를 학습한다.\n",
        "- Multi layer perceptron, Batch normalization, ReLU 를 활용해 네트워크를 설계한다.\n",
        "\n",
        "이번 과정을 통해 여러분은 TensorFlow 를 이용해 분류기를 학습시키고, 학습된 모델의 성능을 검사하는 절차를 익힐 수 있습니다. 전체적인 과정은 다음과 같습니다.\n",
        "\n",
        "- 우리가 다뤄야 할 데이터는 28x28x1 (이미지 높이x이미지 너비x채널)의 흑백 이미지입니다. 즉, 밝기값만을 가지고 있습니다.\n",
        "- 생활속에서 주로 접하게되는 컬러 이미지의 경우 빛의 3원색인 Red, Green, Blue의 3채널로 구성되어 있습니다. 일반적으로 이 3채널을 RGB채널이라고 부르며, 이 채널 값들의 조합으로 색상을 표현하게 됩니다.\n",
        "- DNN(Deep Neural Network)의 입력으로 사용되기 위해서 28$\\times$28$\\times$1의 3차원은 784의 1차원 데이터로(28\\*28\\*1=784) 변환됩니다.\n",
        "- 784차원의 입력 데이터는 DNN을 통과하여 10차원의 의류 종류를 나타내는 출력으로 변환 됩니다(아래의 그림을 참고해 주세요).\n",
        "- 여러분이 만들어야 하는 것은 이 DNN 구조를 TensorFlow를 이용하여 설계하는 과정입니다.\n",
        "<br>\n",
        "<img src=\"https://drive.google.com/uc?id=1N691obHfLeKvP7eJ842EkMovK0O_Nu5E\" width=\"60%\" height=\"60%\">\n",
        "<caption><center>&lt;28$\\times$28$\\times$1의 이미지를 입력으로 받아 옷의 종류를 반환하는 DNN&gt;</center></caption>\n",
        "\n",
        "### 이제부터 본격적으로 프로젝트를 시작하겠습니다.\n",
        "\n",
        "**\"[TODO] 코드 구현\"** 부분의 **\"##코드 시작##\"** 부터 **\"##코드 종료##\"** 구간에 필요한 코드를 작성해주세요. **나머지 작성구간이 명시 되지 않은 구간은 임의로 수정하지 마세요!**\n",
        "\n",
        "\n",
        "**본문 중간중간에 TensorFlow 함수들에 대해 [TensorFlow API 문서](https://www.tensorflow.org/api_docs/python/tf) 링크를 걸어두었습니다. API 문서를 직접 확인하는 일에 익숙해지면 나중에 여러분이 처음부터 모델을 직접 구현해야 할 때 정말 큰 도움이 됩니다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtyPLX-xY1x3"
      },
      "source": [
        "<h1>목차<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Colab-사용자를-위한-안내\" data-toc-modified-id=\"Colab-사용자를-위한-안내-1\">Colab 사용자를 위한 안내</a></span></li><li><span><a href=\"#Neural-Network:-FashoinMNIST-Classifier\" data-toc-modified-id=\"Neural-Network:-FashoinMNIST-Classifier-2\">Neural Network: FashoinMNIST Classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Package-load\" data-toc-modified-id=\"1.-Package-load-2.1\">1. Package load</a></span></li><li><span><a href=\"#2.-하이퍼파라미터-세팅\" data-toc-modified-id=\"2.-하이퍼파라미터-세팅-2.2\">2. 하이퍼파라미터 세팅</a></span></li><li><span><a href=\"#3.-Dataset-load-및-tf.data.Dataset-구축\" data-toc-modified-id=\"3.-Dataset-load-및-tf.data.Dataset-구축-2.3\">3. Dataset load 및 <code>tf.data.Dataset</code> 구축</a></span></li><li><span><a href=\"#4.-데이터-샘플-시각화\" data-toc-modified-id=\"4.-데이터-샘플-시각화-2.4\">4. 데이터 샘플 시각화</a></span></li><li><span><a href=\"#5.-모델-(네트워크)-만들기\" data-toc-modified-id=\"5.-모델-(네트워크)-만들기-2.5\">5. 모델 (네트워크) 만들기</a></span></li><li><span><a href=\"#6.-Loss-function-및-Optimizer-정의\" data-toc-modified-id=\"6.-Loss-function-및-Optimizer-정의-2.6\">6. Loss function 및 Optimizer 정의</a></span></li><li><span><a href=\"#7.-Training\" data-toc-modified-id=\"7.-Training-2.7\">7. Training</a></span></li><li><span><a href=\"#8.-Evaluate-on-test-dataset\" data-toc-modified-id=\"8.-Evaluate-on-test-dataset-2.8\">8. Evaluate on test dataset</a></span></li><li><span><a href=\"#9.-Summary\" data-toc-modified-id=\"9.-Summary-2.9\">9. Summary</a></span></li></ul></li><li><span><a href=\"#Self-Review\" data-toc-modified-id=\"Self-Review-3\">Self-Review</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODKs__rUY1x4"
      },
      "source": [
        "## 1. Package load\n",
        "\n",
        "먼저, 필요한 패키지들을 로드합니다.\n",
        "주로 사용될 대표적인 패키지들의 사용목적은 다음과 같습니다.\n",
        "\n",
        "- `numpy`: Scientific computing과 관련된 여러 편리한 기능들을 제공해주는 라이브러리입니다.\n",
        "- `matplotlib.pyplot`: 데이터 시각화를 위해 사용합니다.\n",
        "- `tensorflow`: TensorFlow 를 로드합니다.\n",
        "- `tensorflow.keras.layers`: 모델의 각 Layer들을 만들기 위해 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USYDapoHY1x5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "4469fb16-d4bb-45b3-84ea-68ea4179d823"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import check_util.checker as checker\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print('tensorflow version: {}'.format(tf.__version__))\n",
        "print('GPU 사용 가능 여부: {}'.format(tf.test.is_gpu_available()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 2.1.0\n",
            "WARNING:tensorflow:From <ipython-input-3-5f41f32b6ac3>:19: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU 사용 가능 여부: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiYhspySY1x9"
      },
      "source": [
        "## 2. 하이퍼파라미터 세팅\n",
        "\n",
        "학습에 필요한 하이퍼파라미터의 값을 초기화해줍니다. 하이퍼파라미터는 뉴럴네트워크를 통하여 학습되는 것이 아니라 학습율(learning rate), 사용할 레이어의 수 등 설계자가 결정해줘야 하는 값들을 의미합니다.\n",
        "\n",
        "미니배치의 크기(`batch_size`), 학습 할 epoch 수(`max_epochs`), 학습률(`learning_rate`) 등의 값들을 다음과 같이 정했습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80uAkzmhY1x-"
      },
      "source": [
        "batch_size = 128\n",
        "max_epochs = 5\n",
        "learning_rate = 0.001\n",
        "num_classes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSQdNT8YY1yB"
      },
      "source": [
        "## 3. Dataset load 및 `tf.data.Dataset` 구축\n",
        "\n",
        "[Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)는 10개의 필기체 숫자로 구성된 [MNIST 데이터](http://yann.lecun.com/exdb/mnist/)의 Fashion 버젼(version)으로 보시면 됩니다. 프로그래밍을 처음 접해보는 사람들이 주로 가장 먼저 실습해 보는 것이 \"Hello, World\"를 출력해보는 것이죠. 머신러닝을 처음 접해보시는 분들에게 이 \"Hello, Wolrd\"를 출력해보는 작업이 MNIST 데이터를 분류해보는 것이라고 비유할 수 있을 것 같습니다. 그만큼 많은 사람들이 쉽게 다운로드 받아 테스트 해볼 수 있고, 분류기들의 성능 비교용으로도 많이 사용됩니다.<br>\n",
        "그러나 현재 MNIST 분류는 머신러닝 기술의 발전하면서 너무 쉬운 문제가 됐고, MNIST에서 좋은 성능을 보이는 분류기가 다른 데이터에서도 잘 작동한다고 말하기 어려운 환경이 됐습니다. 그에대한 한가지 대안으로 제시된 데이터가 Fashion-MNIST 입니다. <br>\n",
        "Fashion-MNIST는 MNIST와 동일한 크기의 데이터(10개의 부류, 60,000개의 학습, 10,000개의 테스트 데이터)이지만 MNIST보다 분류하기 어려운 의류 영상데이터 입니다. Fashion-MNIST의 데이터 부류는 T-Shirts, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Bag, Ankle boot로 10개의 입니다.\n",
        "\n",
        "실습을 위해 Fashion-MNIST 데이터셋을 정의해주고, 전체 데이터셋을 미니배치 단위로 뉴럴넷에 공급해주도록 `tf.data.Dataset`을 정의합니다.\n",
        "\n",
        "### Fashion-MNIST 데이터셋 load\n",
        "\n",
        "* [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) 데이터는 `tf.keras.datasets`에서 기본 제공됩니다.\n",
        "* 아래 코드블록의 5번째 줄은 `train_data`의 값의 범위인 [0, 255]의 범위를 [0, 1]의 범위로 조절 합니다.\n",
        "* 6번째 줄은 이미지 형태의 (28(높이), 28(너비)) 데이터를 네트워크의 입력으로 넣기 위해 1차원의 28*28=784 데이터로 변경합니다.\n",
        "* 10번째 줄부터 `train_data`를 변환한 방식으로 `test_data`를 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xWkPlRKY1yC"
      },
      "source": [
        "# Load training and eval data from tf.keras\n",
        "(train_data, train_labels), (test_data, test_labels) = \\\n",
        "    tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "train_data = train_data / 255.\n",
        "train_data = train_data.reshape([-1, 28 * 28])\n",
        "train_data = train_data.astype(np.float32)\n",
        "train_labels = train_labels.astype(np.int32)\n",
        "\n",
        "test_data = test_data / 255.\n",
        "test_data = test_data.reshape([-1, 28 * 28])\n",
        "test_data = test_data.astype(np.float32)\n",
        "test_labels = test_labels.astype(np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K-CAcp2Y1yG"
      },
      "source": [
        "### <font color='red'>[TODO] 코드 구현</font>\n",
        "\n",
        "다음을 읽고 코드를 완성해보세요. 단, \"## 코드 시작 ##\"과 \"## 코드 종료 ##\" 사이에 주어진 변수 명으로 코드를 작성하세요!\n",
        "\n",
        "`tf.data.Dataset`을 이용하여 input pipeline 구축하여 봅시다.\n",
        "\n",
        "TensorFlow의 tf.data API는 네트워크 입력을 만들기 위한 복잡한 데이터 처리과정을 단순화 시켜줍니다.\n",
        "본 실습에서는 데이터 입력 파이프라인을 쉽게 설계할 수 있는 tf.data.Dataset을 이용할 겁니다.\n",
        "실습에 사용될 tf.data.Dataset 내에서 사용할 API들은 다음과 같습니다.\n",
        "\n",
        "* `tf.data.Dataset`에 대한 자세한 설명은 [Importing Data](https://www.tensorflow.org/guide/datasets) 페이지 참고 바랍니다.\n",
        "* `tf.data.Dataset`의 다양한 method들은 [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) 페이지에서 살펴보시면 좋습니다.\n",
        "<br>\n",
        "<br>\n",
        "* `tf.data.Dataset.from_tensor_slices`: numpy타입의 데이터를 tf.data.Dataset 형태의 데이터로 변환시켜줍니다.\n",
        "* `tf.data.Dataset.shuffle`: 데이터를 무작위로 섞어 줍니다.\n",
        "  * `shuffle`함수의 매개변수로 `buffer_size`가 있습니다. 이는 버퍼를 `buffer_size` 크기의 요소(elements)로 채운 다음 이 버퍼에서 무작위로 샘플링하고 선택된 요소를 새로운 요소로 대체합니다. 완벽한 섞임을 위해서는 데이터 세트의 전체 크기보다 크거나 같은 버퍼 크기(`buffer_size`)가 필요합니다.\n",
        "* `tf.data.Dataset.batch`: 읽어들일 데이터의 배치크기(batch_size)를 결정합니다.\n",
        "* [`repeat`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#repeat)를 이용하여 재사용할 수 있게 만들어봅시다.\n",
        "\n",
        "\n",
        "**tf.data.Dataset API를 이용하여 다음과 같은 작업을 수행해야 합니다**\n",
        "* [`tf.data.Dataset.from_tensor_slices`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices) API를 이용하여 train_data 및 train_labels데이터를 `tf.data.Dataset` 형태로 만들어봅시다. 마찬가지로 test_data, test_labels데이터도 `tf.data.Dataset` 형태로 만들어봅니다. 이미지 한장에 해당하는 부류 레이블이 한 세트로 묶어져야 합니다.\n",
        "* `tf.data.Dataset.shuffle`: 데이터셋을 shuffle 시켜줍니다.\n",
        "* `tf.data.Dataset.batch`: 데이터셋의 batch_size를 결정합니다.\n",
        "* `tf.data.Dataset.repeat`: 데이터셋을 다 사용하더라도 반복해서 사용할 수 있게합니다. 값을 지정하지 않으면 무한히 반복할 수 있습니다.\n",
        "\n",
        "**아래의 코드블록은 tf.data.Dataset을 만드는 간단한 에제와 데이터 추출과정을 보여줍니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCD7M2WOY1yG"
      },
      "source": [
        "# tf.data.Dataset 만드는 간단한 예제\n",
        "temp_dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4])\n",
        "temp_dataset = temp_dataset.shuffle(100)\n",
        "temp_dataset = temp_dataset.batch(2)\n",
        "temp_dataset = temp_dataset.repeat(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWnEmYHhY1yK"
      },
      "source": [
        "# 실제 data를 추출하는 과정\n",
        "for epoch in range(3):\n",
        "    count = 0 # 무한루프 방지용\n",
        "    for step, data in enumerate(temp_dataset):\n",
        "        print(\"epoch: {}  step: {}  data: {}\".format(\n",
        "              epoch+1, step+1, data))\n",
        "        count += 1\n",
        "        if count > 10:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJTC56irY1yO"
      },
      "source": [
        "`test`데이터 셋은 shuffle할 필요가 없습니다.\n",
        "* `train`시 shuffle하는 목적은 mini-batch gradient descent를 하기 위해 mini-batch 데이터를 random 하게 뽑는 것입니다.\n",
        "* `test` 데이터 셋의 목적은 성능을 평가하기 위함입니다. 그렇기 때문에 `test`데이터 셋은 shuffle할 필요가 없습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gox5GvGkY1yO"
      },
      "source": [
        "**이제 모델에게 전달할 데이터 공급 코드를 작성해보세요! \"<font color='45A07A'>## 코드 시작 ##</font>\"과 \"<font color='45A07A'>## 코드 종료 ##</font>\" 사이의 <font color='075D37'>None</font> 부분을 채우시면 됩니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_5cXsdJY1yP",
        "outputId": "6d29d1ef-0751-4060-e85e-548f3e979020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# for train\n",
        "N = len(train_data)\n",
        "\n",
        "## 코드 시작 ##\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
        "train_dataset = train_dataset.shuffle(10)\n",
        "train_dataset = train_dataset.batch(128)\n",
        "train_dataset = train_dataset.repeat(3)\n",
        "## 코드 종료 ##\n",
        "\n",
        "print(train_dataset)\n",
        "\n",
        "# for test\n",
        "## 코드 시작 ##\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
        "test_dataset = test_dataset.batch(128)\n",
        "test_dataset = test_dataset.repeat(3)\n",
        "## 코드 종료 ##\n",
        "\n",
        "print(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<RepeatDataset shapes: ((None, 784), (None,)), types: (tf.float32, tf.int32)>\n",
            "<RepeatDataset shapes: ((None, 784), (None,)), types: (tf.float32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf82CwbMY1yS"
      },
      "source": [
        "`print(train_dataset)` 및 `print(test_dataset)`의 결과는 다음과 같습니다.\n",
        "\n",
        "```\n",
        "<RepeatDataset shapes: ((None, 784), (None,)), types: (tf.float32, tf.int32)>\n",
        "<RepeatDataset shapes: ((None, 784), (None,)), types: (tf.float32, tf.int32)>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHsOd0s8Y1yT"
      },
      "source": [
        "아래의 코드를 실행해 코드를 성공적으로 완성했는지 확인해보세요.\n",
        "\n",
        "별다른 문제가 없다면 이어서 진행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU7aRRzpY1yU",
        "outputId": "196c9040-c0e2-4e2f-954e-61fe6c368c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "checker.train_dataset_check(train_dataset)\n",
        "checker.test_dataset_check(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_dataset을 잘 구현하셨습니다! 이어서 진행하셔도 좋습니다.\n",
            "test_dataset을 잘 구현하셨습니다! 이어서 진행하셔도 좋습니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKC3x_LZY1yW"
      },
      "source": [
        "## 4. 데이터 샘플 시각화\n",
        "\n",
        "FashionMNIST는 MNIST와 마찬기지로 총 10개의 클래스로 구성되어 있으며 티셔츠, 바지 등 패션과 관련된 아이템들을 28 $\\times$ 28 크기의 흑백 이미지로 구성한 데이터셋입니다.\n",
        "\n",
        "아래의 코드블록은 Fashion-MNIST 데이터를 시각화 합니다.\n",
        "\n",
        "`labels_map`에 각 클래스의 이름과 인덱스를 파이썬 딕셔너리(dictionary)로 저장했습니다.\n",
        "7번재 줄부터 for문을 이용하여 `train_data`에 속한 데이터를 무작위로 25개 추출한 뒤 5$\\times$5 격자 형태로 출력합니다.\n",
        "\n",
        "`matplotlib`은 2D 시각화를 위한 라이브러리입니다. `matplotlib.pyplot`의 figure()를 통해 그림을 그릴 도화지를 생성할 수 있습니다. 생성된 figure 객체의 `add_subplot` 함수를 통해 전체 도화지 속에 일부 도면을 삽입할 수 있습니다. 큰 도화지 위에 작은 그림들을 구역마다 그리는 것입니다. 코드를 실행해 생성된 그림을 먼저 보시고 코드를 함께 보면 더욱 이해하기 쉬울 것입니다.\n",
        "`matplotlib.pyplot`의 더 다양한 기능을 살펴보고 싶으면 [이곳](https://matplotlib.org/3.1.0/tutorials/introductory/pyplot.html)을 참고해주세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qwfmyJ5Y1yX",
        "outputId": "36918a2b-e628-4b4f-97c5-fde6e42f6823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "source": [
        "labels_map = {0: 'T-Shirt', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat',\n",
        "              5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle Boot'}\n",
        "columns = 5\n",
        "rows = 5\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "\n",
        "for i in range(1, columns*rows+1):\n",
        "    data_idx = np.random.randint(len(train_data))\n",
        "    img = train_data[data_idx].reshape([28, 28])\n",
        "    label = labels_map[train_labels[data_idx]]\n",
        "\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.title(label)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAHRCAYAAADqjfmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFfiD0nEcx3Eq8Ael4ziO41Tw/wH6bYiuCW920wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x576 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHoUyu5NY1ya"
      },
      "source": [
        "## 5. 모델 (네트워크) 만들기\n",
        "\n",
        "학습시킬 뉴럴네트워크를 설계합니다.\n",
        "이번 실습에서는 Multi Layer Perceptron(MLP) 레이어를 2개 쌓아 네트워크를 설계할 것입니다.\n",
        "\n",
        "MLP는 아래의 그림과 같이 한 레이어의 모든 뉴런이 다음 레이어의 뉴런과 완전히 연결된 계층(Fully connected layer 또는 Dense layer)입니다.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1KuQg548RFXMm1Kih46IXkKLO-q76lBdQ\" width=\"800px\" height=\"400px\" />\n",
        "\n",
        "\n",
        "한편, MLP의 레이어를 깊게 쌓을 때에는 반드시 비선형 activation function이 필요합니다.\n",
        "이번 실습에서는 ReLU를 사용 할 것입니다.\n",
        "ReLU는 아래의 그림과 같이 음수의 입력에 대해서는 0, 양수의 입력에 대해서는 입력값을 그대로 출력하는 함수입니다.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=14hYX4UF0Ony8apMZmN7IEkQHqP6PB-ne\" width=\"400px\" height=\"400px\" /><caption><center>ReLU의 출력</center></caption>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ppe0pXkY1yb"
      },
      "source": [
        "### <font color='red'>[TODO] 코드 구현</font>\n",
        "\n",
        "다음을 읽고 코드를 완성해보세요.\n",
        "\n",
        "- 첫번째 dense layer의 입력 feature 갯수는 입력 이미지의 픽셀 갯수인 28 $\\times$ 28로, 출력 feature 갯수는 512로 하겠습니다.\n",
        "- 첫번째 dense layer와 ReLU 사이에 Batch normalization(['Lab-10-4'](https://www.youtube.com/watch?v=-VwtLBp2FRs&list=PLQ28Nx3M4Jrguyuwg4xe9d9t2XE639e5C&index=30))을 적용해보세요.\n",
        "- 그리고 첫번째 dense layer 이후에는 ReLU 함수를 적용해보세요.\n",
        "- 두번째 dense layer의 출력 feature 갯수는 데이터의 class 갯수인 10으로 지정해야 합니다. (혹은 `2. 하이퍼파라미터 세팅`장에서 정의한 `num_classes` 로 지정합니다.)\n",
        "- 두번째 dense layer 이후에는 ReLU activation function을 적용하지 않습니다. Classification 네트워크의 마지막 activation function은 주로 softmax 함수가 적용되기 때문입니다. dense layer에 parameter로 activation을 지정해보세요.\n",
        "\n",
        "- 실습에 사용 될 **tf.keras.layers API** (**자세한 사용법은 레이어명 클릭**)\n",
        "  - [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) : 일반적인 완전연결(densely-connected) 레이어\n",
        "  - [`BatchNormalization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) : 배치 노말라이제이션 레이어\n",
        "  - [`ReLU`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU) : ReLU 활성화 함수 레이어"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD3D3lAsY1yc"
      },
      "source": [
        "### [`tf.keras.Sequential()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential)을 이용하여 모델 만들기\n",
        "\n",
        "* `tf.keras.model.Sequential()`와 `tf.keras.Sequential()`은 같은 API\n",
        "* `Sequential`은 해당 레이어의 output이 그대로 다음 레이어의 input이 되는 구조의 모델을 만들 때 씁니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLV0iCw9Y1yd"
      },
      "source": [
        "### <font color='blue'> [Tensorflow 1.x 버전과 2.x 버전의 차이점] </font>\n",
        "\n",
        "- Tensorflow 1.x 버전과 2.x 버전의 가장 큰 차이점은 eager모드가 default로 변경되었다는 점입니다. 이전의 tensorflow에서는 계산 그래프를 지정해준 다음 session을 열어서 계산을 수행하는 방법을 이용했습니다. 2.x 버전으로 바뀌면서 eager 모드가 default가 되었고 keras의 high-level api가 표준 api로 정해졌습니다.\n",
        "- 앞으로 수행할 프로젝트에서는 tf.keras 기반의 sequential 구조를 사용합니다. sequential 구조는 레고 쌓기 비유가 자주 사용됩니다. layer들을 하나씩 하나씩 add 하면서 전체 model을 완성하면 되기 때문입니다. 편하고 간결한 코드 때문에 단순한 모델에서 큰 장점이 있지만 복잡한 모델에서는 class 형식으로 model을 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PtVYdhqY1ye"
      },
      "source": [
        "model = tf.keras.Sequential() # Sequential 모델 생성"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yFsU6lnY1yh"
      },
      "source": [
        "**tf.keras.layers API 를 이용해 모델 코드를 작성해보세요! \"<font color='45A07A'>## 코드 시작 ##</font>\"과 \"<font color='45A07A'>## 코드 종료 ##</font>\" 사이의 <font color='075D37'>None</font> 부분을 채우시면 됩니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7WuIBXKY1yi"
      },
      "source": [
        "## 코드 시작 ##\n",
        "model.add(tf.keras.layers.Dense(512, input_shape=(28,)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.ReLU(max_value=None))\n",
        "model.add(tf.keras.layers.Dense(num_classes, activation = 'softmax'))\n",
        "## 코드 종료 ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fdn2eePY1yk"
      },
      "source": [
        "아래의 코드를 실행해 코드를 성공적으로 완성했는지 확인해보세요.\n",
        "\n",
        "별다른 문제가 없다면 이어서 진행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc8lxfJZY1yl",
        "outputId": "fd9f61cd-77c6-4a16-ae23-189d0b4e2b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "checker.model_check(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "네트워크를 잘 구현하셨습니다! 이어서 진행하셔도 좋습니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1gK3y2_Y1yp"
      },
      "source": [
        "### <font color='blue'> [잠깐! 퀴즈 한 번 풀어볼까요?] </font>\n",
        "\n",
        "***퀴즈 #1:*** 첫번째 MLP 레이어에서 학습되는 파라미터의 개수는?\n",
        "\n",
        "***정답 #1:*** (weight 개수 + bias 개수) = (784 x 512 + 512) = 401408 + 512 = 401920\n",
        "\n",
        "모델의 학습 파라미터 개수는 왜 중요할까요? 학습할 파라미터 개수가 많아진다는 것은 무엇을 의미할까요? 학습할 파라미터가 많다는 것은 모델이 더욱 복잡한 함수를 표현할 수 있게 됨을 의미합니다. 따라서 학습할 파라미터가 많으면 모델이 더 복잡한 문제를 풀 수 있는 능력을 갖추게 되는 것입니다. 하지만 모델의 학습 파라미터가 많아지면 학습에 필요한 데이터 개수 또한 증가하게 됩니다. 예를 들어 $x= 1, y=2$ 인 데이터가 있을 때, $y = w_1 x$ (학습 파라미터가 1개인 모델) 와 $y= w_1 x + w_2$ (학습 파라미터가 2개인 모델)의 매개변수 값을 각각 구한다고 가정해보겠습니다. 첫번째 식은 $2=w_1 \\times 1$ 로 해(solution)가 구해지지만 두번째 식은 하나의 데이터로는 두 개의 파라미터의 해를 구할 수 없겠죠."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfoWB0OeY1yq"
      },
      "source": [
        "***퀴즈 #2 :*** Xavier normal initialization은 표준편차가 **X**인 정규분포로 weight를 초기화하는 방법입니다. 다음 중 **X**에 들어갈 값으로 올바른 것은? (단, $n_{in}$과 $n_{out}$은 각각 입력, 출력 뉴런의 갯수)\n",
        "\n",
        "① $\\sqrt{\\frac{2}{n_{in} + n_{out}}}$\n",
        "② $\\sqrt{\\frac{n_{in} + n_{out}}{2}}$\n",
        "③ $\\sqrt{\\frac{2}{n_{in}}}$\n",
        "④ $\\sqrt{\\frac{n_{in}}{2}}$\n",
        "\n",
        "***정답 :*** ①"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuKmlQ_8Y1yr"
      },
      "source": [
        "### 데이터의 일부를 넣어서 model 체크 & summary 하기\n",
        "\n",
        "모델을 학습 하기전에 모델이 잘 동작하는지 확인해 보겠습니다. 아래의 코드블록은 배치크기만큼 영상을 가져온 후 이 중 3개를 영상을 모델에 입력해 보는 코드입니다. 그리고 `model.summary()`를 통해 생성된 모댈의 정보를 확인하실 수 있을 겁니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvG497WOY1ys",
        "outputId": "d7491a8e-e7a9-48f3-8360-9691fbc37ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "for images, labels in train_dataset.take(1):\n",
        "    print(\"predictions: \", model(images[0:3]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape Tensor(\"dense_input:0\", shape=(None, 28), dtype=float32) for input (None, 28), but it was re-called on a Tensor with incompatible shape (3, 784).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-1d289313348e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictions: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5614\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5615\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5616\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5617\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5618\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [3,784], In[1]: [28,512] [Op:MatMul]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Z_K0CGY1yu",
        "outputId": "b9e0692a-e182-45a3-f1ee-258f71a9b99c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               14848     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 22,026\n",
            "Trainable params: 21,002\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQWQVxTcY1yx"
      },
      "source": [
        "## 6. Loss function 및 Optimizer 정의\n",
        "\n",
        "생성한 모델을 학습 시키기 위해서 손실함수를 정의해야 합니다. 뉴럴네트워크는 경사하강(gradient descent)방법을 이용하여 손실함수의 값을 줄이는 방향으로 파라미터를 갱신(update) 하게 됩니다. 또한 효과적인 경사하강 방법을 적용하기 위해 옵티마이져를 함께 사용할 겁니다.\n",
        "\n",
        "### <font color='red'>[TODO] 코드 구현</font>\n",
        "\n",
        "다음을 읽고 코드를 완성해보세요.\n",
        "- `compile` 앞서 정의한 model에서 training을 위해 loss와 optimizer를 지정해주세요. [tf.Keras.Model.compile()](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile)\n",
        "- `loss` [SparseCategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy)와 [Cross Entropy Loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy)의 차이점을 읽고 데이터에 맞는 loss를 정의하세요.\n",
        "- `optimizer` 변수에 [Adam optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam)를 앞에서 지정한 learning rate에 맞게 정의하세요.\n",
        "- `metrics` accuracy를 정의하세요.\n",
        "\n",
        "### <font color='blue'> [Tensorflow 1.x 버전과 2.x 버전의 차이점] </font>\n",
        "\n",
        "- `loss`, `optimizer`, `metric` 등을 `model.compile`을 통해 한꺼번에 쉽고 가독성 있게 설정할 수 있게 되었습니다.\n",
        "\n",
        "**이제 손실함수와 옵티마이저 코드를 작성해보세요! \"<font color='45A07A'>## 코드 시작 ##</font>\"과 \"<font color='45A07A'>## 코드 종료 ##</font>\" 사이의 <font color='075D37'>None</font> 부분을 채우시면 됩니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbw8u0yHY1yx"
      },
      "source": [
        "# model compile with optimizer, loss, metrics\n",
        "\n",
        "## 코드 시작 ##\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss =tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics = ['accuracy'])\n",
        "## 코드 종료 ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAYO5TExY1y0"
      },
      "source": [
        "아래의 코드를 실행해 코드를 성공적으로 완성했는지 확인해보세요.\n",
        "\n",
        "별다른 문제가 없다면 이어서 진행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKJGjskGY1y0",
        "outputId": "4ae20c7f-fee5-4f0b-b64b-bc0d5afc9fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "checker.compile_check(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compile을 잘 정의하셨습니다! 이어서 진행하셔도 좋습니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFDH06nJY1y3"
      },
      "source": [
        "## 7. Training\n",
        "\n",
        "이제 모델에 데이터를 미니배치 단위로 제공해서 학습을 시킬 단계입니다.\n",
        "\n",
        "### <font color='red'>[TODO] 코드 구현</font>\n",
        "\n",
        "다음을 읽고 코드를 완성해보세요. 단, \"# 코드 시작\"과 \"# 코드 종료\" 사이에 주어진 변수 명으로 코드를 작성하세요!\n",
        "- [`tf.keras.Model의 Method인 fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)을 이용하여 학습을 시작하세요.\n",
        "- `tf.data.Dataset`으로 만든 객체인 `train_dataset`을 input으로 넣어주세요.\n",
        "- input으로 tf.data를 이용하는 경우 `steps_per_epoch` 을 지정해주어야 합니다. train_data의 길이를 batch_size 크기로 나눈 값을 지정해주세요.\n",
        "- `epochs`를 미리 변수에 담아둔 값으로 지정해주세요.\n",
        "\n",
        "**이제 각 스텝에 따라 훈련 단계 코드를 작성해보세요! \"<font color='45A07A'>## 코드 시작 ##</font>\"과 \"<font color='45A07A'>## 코드 종료 ##</font>\" 사이의 <font color='075D37'>None</font> 부분을 채우시면 됩니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BklnaB3PY1y4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "7d172a4f-91a0-4819-84ba-748f29d5a2d8"
      },
      "source": [
        "## 코드 시작 ##\n",
        "model.fit(train_dataset, steps_per_epoch = train_data.shape[0]//batch_size, epochs=max_epochs)\n",
        "## 코드 종료 ##"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-821d0c1ea9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m## 코드 종료 ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# Note that the dataset instance is immutable, its fine to reusing the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mstandardize_function\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    682\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[0;32m-> 1591\u001b[0;31m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3926\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3139\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:582 standardize_input_data\n        str(data_shape))\n\n    ValueError: Error when checking input: expected dense_input to have shape (28,) but got array with shape (784,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i44MQMtY1y7"
      },
      "source": [
        "위의 로그에 출력되는 마지막 학습 Accuracy가 90% 전후로 나오면 코드를 잘 완성한 것입니다.\n",
        "\n",
        "만약에 학습이 진행이 되지 않는다면 지문과 지문에 나와있는 API문서 링크를 다시 한 번 꼼꼼히 살펴보시기 바랍니다.\n",
        "\n",
        "문제가 없다면 다음으로 이어서 진행하시면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQnraqjZY1y7"
      },
      "source": [
        "checker.accuracy_check(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlmizNpTY1y-"
      },
      "source": [
        "## 8. Evaluate on test dataset\n",
        "\n",
        "마지막으로 학습된 모델의 성능을 테스트할 차례입니다.\n",
        "\n",
        "tf.keras.Model의 하위 method인 [`evaluate`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate)을 이용하면 쉽게 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trfIvZZ2Y1y-"
      },
      "source": [
        "loss,accuracy = model.evaluate(test_dataset, steps = len(test_data)//batch_size)\n",
        "print('test loss is {}'.format(loss))\n",
        "print('test accuracy is {}'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B0OOjcqY1zB"
      },
      "source": [
        "최종 성능이 대략 85% 전후로 나오면 학습이 잘된 것으로 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXDj2NCDY1zC"
      },
      "source": [
        "checker.test_check(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdF1yYtGY1zF"
      },
      "source": [
        "### output 확인하기\n",
        "Accuracy같은 모델의 성능이 아닌 실제로 output이 어떻게 나오는지 확인하려면 두 가지 방법이 있습니다.\n",
        "\n",
        "`predict`를 이용하는 방법이 있고 model에 `input을 직접 넣는 방법`이 있습니다.\n",
        "\n",
        "> `model.predict(tf.reshape(images[0], (1,-1)))`\n",
        "\n",
        "> `model(tf.reshape(images[0], (1,-1)), training=False)`\n",
        "\n",
        "- reshape을 해주는 이유는 model이 input으로 받는 shape이 `(batch_size, input_shape)` 형식이기 때문입니다.\n",
        "\n",
        "- 모델에 `training` argument를 `False`로 주는 이유는 다음과 같습니다. `Batch normalization`, `dropout`과 같은 layer들은 training을 할 때와 test를 할 때 작동하는 방식이 다르기 때문입니다. 그래서 현재 `mode`가 `training`중인지 아닌지를 argument로 넘겨주는 것입니다.\n",
        "\n",
        "- inference시에 `training` parameter의 default값은 False입니다. True로 바꾸면 어떻게 값이 변하는지 확인해보세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPEVHD4xY1zF"
      },
      "source": [
        "model.predict(tf.reshape(images[0], (1,-1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTKeNiRAY1zJ"
      },
      "source": [
        "model(tf.reshape(images[0], (1,-1)), training = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-3PJI9wY1zL"
      },
      "source": [
        "model(tf.reshape(images[0], (1,-1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDvdHToRY1zN"
      },
      "source": [
        "model(tf.reshape(images[0], (1,-1)), training = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T11Zc3CxY1zP"
      },
      "source": [
        "학습된 모델의 예측 결과를 시각화하면 다음과 같습니다. label이 <font color='blue'>파란색</font>으로 표시되면 모델이 정확한 예측을 한 것이고 <font color='red'>빨간색</font>으로 표시되면 틀린 예측을 한 것입니다. 틀린 경우에는 모델의 예측과 함께 실제 정답을 표기해두었습니다. (ex. 오답/정답)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3FLZq9bY1zQ"
      },
      "source": [
        "test_batch_size = 25\n",
        "batch_index = np.random.choice(len(test_data), size=test_batch_size, replace=False)\n",
        "\n",
        "batch_xs = test_data[batch_index]\n",
        "batch_ys = test_labels[batch_index]\n",
        "y_pred_ = model(batch_xs, training=False)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i, (px, py, y_pred) in enumerate(zip(batch_xs, batch_ys, y_pred_)):\n",
        "    p = fig.add_subplot(5, 5, i+1)\n",
        "    if np.argmax(y_pred) == py:\n",
        "        p.set_title(\"{}\".format(labels_map[py]), color='blue')\n",
        "    else:\n",
        "        p.set_title(\"{}/{}\".format(labels_map[np.argmax(y_pred)],\n",
        "                               labels_map[py]), color='red')\n",
        "    p.imshow(px.reshape(28, 28))\n",
        "    p.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Sh5yy-Y1zU"
      },
      "source": [
        "## 9. Summary\n",
        "\n",
        "여기까지 오신 여러분 잘하셨습니다!\n",
        "\n",
        "우리는 이번 실습을 통해 다음과 같은 내용을 학습했습니다.\n",
        "\n",
        "- Multi layer perceptron을 설계할 수 있다.\n",
        "- 네트워크에 ReLU, Batch normalization를 적용할 수 있다.\n",
        "- `tf.data.Dataset`을 이용하여 데이터입력 파이프라인(input pipeline)을 만들 수 있다.\n",
        "- 손실함수(loss function)과 옵티마이져(optimizer)를 정의할 수 있다.\n",
        "- 손실(loss)를 측정하고 경사(gradient)를 계산해 모델 파라미터를 업데이트할 수 있다.\n",
        "- 학습한 모델의 성능을 테스트 할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xGixiStY1zU"
      },
      "source": [
        "# Self-Review\n",
        "\n",
        "학습 환경에 맞춰 알맞는 제출방법을 실행하세요!\n",
        "\n",
        "### 로컬 환경 실행자\n",
        "\n",
        "1. 모든 실습 완료 후, Jupyter Notebook 을 `Ctrl+S` 혹은 `File > Save and checkpoint`로 저장합니다.\n",
        "2. 제일 하단의 코드를 실행합니다. 주의할 점은 Jupyter Notebook 의 파일이름을 수정하시면 안됩니다! 만약에 노트북 이름을 수정했다면 \"tensorflow-dnn-project\" 로 바꿔주시길 바랍니다. 모든 평가 기준을 통과하면, 함수 실행 후 프로젝트 \"submit\" 디렉토리와 압축된 \"submit.zip\"이 생깁니다. \"dnn_submission.tsv\" 파일을 열고 모두 Pass 했는지 확인해보세요!\n",
        "    * \"dnn_submission.tsv\" : 평가 기준표에 근거해 각 세부항목의 통과여부(Pass/Fail) 파일\n",
        "    * \"dnn_submission.html\" : 여러분이 작성한 Jupyter Notebook 을 html 형식으로 전환한 파일\n",
        "3. 코드 실행결과 안내에 따라서 `submit.zip` 파일을 확인하시고 제출해주시길 바랍니다.\n",
        "\n",
        "### Colab 환경 실행자\n",
        "\n",
        "1. 모든 실습 완료 후, Jupyter Notebook 을 `Ctrl+S` 로 저장합니다.\n",
        "2. 제일 하단의 코드를 실행합니다. 코드 실행결과 안내에 따라서 재작성하거나 다음스텝으로 넘어갑니다. 모든 평가 기준을 통과하면, 함수 실행 후 프로젝트 \"submit\" 디렉토리와 압축된 \"dnn_submission.tsv\"만 생깁니다. \"dnn_submission.tsv\" 파일을 열고 모두 Pass 했는지 확인해보세요!\n",
        "    * \"dnn_submission.tsv\" : 평가 기준표에 근거해 각 세부항목의 통과여부(Pass/Fail) 파일\n",
        "3. 프로젝트를 저장한 드라이브의 `submit` 폴더에서 `dnn_submission.tsv` 파일을 다운 받습니다.\n",
        "4. Colab Notebook 에서 `파일 > .ipynb 다운로드`를 통해서 노트북을 다운로드 받습니다.\n",
        "5. 로컬에서 Jupyter Notebook 프로그램을 실행시킵니다.\n",
        "6. 4번 스텝에서 다운받은 노트북을 열고 `File > Download as > HTML(.html)` 로 재 다운로드 합니다.\n",
        "7. 3번 스텝에서 받은 파일과 6번 스텝에서 받은 파일을 하나의 폴더에 넣고, `submit.zip` 이라는 이름으로 압축하고 제출해주시길 바랍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91jQtlzKY1zV"
      },
      "source": [
        "import check_util.submit as submit\n",
        "submit.process_submit()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}